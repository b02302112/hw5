title   <- title[-emptyId]
empty   <- author == "-"
date    <- xpathSApply(xmldoc, "//div[@class='date']", xmlValue)
response<- xpathSApply(xmldoc, "//div[@class='nrec']", xmlValue)
path    <- xpathSApply(xmldoc, "//div[@class='title']/a//@href")
author  <- xpathSApply(xmldoc, "//div[@class='author']", xmlValue)
date    <- date[-emptyId]
alldata <- data.frame(title, author, path, date, response)
response<- response[-emptyId]
author  <- author[!empty]
author  <- author[!empty]
date    <- xpathSApply(xmldoc, "//div[@class='date']", xmlValue)
date    <- date[-emptyid]
response<- xpathSApply(xmldoc, "//div[@class='nrec']", xmlValue)
response<- response[-emptyid]
path    <- xpathSApply(xmldoc, "//div[@class='title']/a//@href")
alldata <- data.frame(title, author, path, date, response)
emptyid <- which(title == "(本文已被刪除) [brukling]")
title   <- title[-emptyId]
author  <- xpathSApply(xmldoc, "//div[@class='author']", xmlValue)
empty   <- author == "-"
author  <- author[-empty]
date    <- xpathSApply(xmldoc, "//div[@class='date']", xmlValue)
date    <- date[-emptyid]
response<- xpathSApply(xmldoc, "//div[@class='nrec']", xmlValue)
response<- response[-emptyid]
path    <- xpathSApply(xmldoc, "//div[@class='title']/a//@href")
alldata <- data.frame(title, author, path, date, response)
empty
!empty
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
View(alldata)
source('~/.active-rstudio-document', echo=TRUE)
install.packages("tmcn")
setwd("~/Desktop/Junuralism")
setwd("~/Desktop/Junuralism/TextMining")
rm(list=ls(all.names = TRUE))
#install.packages("http://download.r-forge.r-project.org/src/contrib/tmcn_0.1-4.tar.gz", repos = NULL, type = "source")
library(tmcn)
#install.packages("rvest")
library(rvest)
URL = "https://www.ptt.cc/bbs/IA/index.html"
html = read_html(URL)
title = html_nodes(html, "a")
href = html_attr(title, "href")
data = data.frame(title = toUTF8(html_text(title)), href = href)
View(data)
getContent <- function(href)
{
subURL = paste0("http://www.ptt.cc", href)
subhtml = read_html(subURL)
content = html_nodes(subhtml, "div#main-content.bbs-screen.bbs-content")
return(toUTF8(html_text(content)))
}
#practice
#getContent(data$href[14])
#clean
data = data[-c(1:10),]
#getContent(data$href[alltext])
allText = sapply(data$href, getContent)
allText
write.table(allText, "mydata.txt")
rm(list=ls(all.names = TRUE))
library(NLP)
library(tm)
library(jiebaRD)
library(jiebaR)
library(RColorBrewer)
library(wordcloud)
filenames <- list.files(getwd(), pattern="*.txt")
files <- lapply(filenames, readLines)
docs <- Corpus(VectorSource(files))
#Corpus是一種文字檔資料格式--文本
#移除可能有問題的符號-Corpus文本清理與改寫
toSpace <- content_transformer(function(x, pattern) {
return (gsub(pattern, " ", x))
}
)
docs <- tm_map(docs, toSpace, "的")
docs <- tm_map(docs, toSpace, "發信站")
docs <- tm_map(docs, toSpace, "文章")
docs <- tm_map(docs, toSpace, "作者")
docs <- tm_map(docs, toSpace, "推")
docs <- tm_map(docs, toSpace, "了")
docs <- tm_map(docs, toSpace, "不")
docs <- tm_map(docs, toSpace, "也")
docs <- tm_map(docs, toSpace, "都")
docs <- tm_map(docs, toSpace, "在")
docs <- tm_map(docs, toSpace, "有")
docs <- tm_map(docs, toSpace, "就")
docs <- tm_map(docs, toSpace, "會")
docs <- tm_map(docs, toSpace, "跟")
docs <- tm_map(docs, toSpace, "沒")
docs <- tm_map(docs, toSpace, "到")
docs <- tm_map(docs, toSpace, "為")
docs <- tm_map(docs, toSpace, "他")
docs <- tm_map(docs, toSpace, "們")
docs <- tm_map(docs, toSpace, "說")
docs <- tm_map(docs, toSpace, "與")
docs <- tm_map(docs, toSpace, "上")
docs <- tm_map(docs, toSpace, "對")
docs <- tm_map(docs, toSpace, "但")
docs <- tm_map(docs, toSpace, "只")
docs <- tm_map(docs, toSpace, "還")
docs <- tm_map(docs, toSpace, "和")
docs <- tm_map(docs, toSpace, "或")
docs <- tm_map(docs, toSpace, "從")
docs <- tm_map(docs, toSpace, "以")
docs <- tm_map(docs, toSpace, "被")
docs <- tm_map(docs, toSpace, "讓")
docs <- tm_map(docs, toSpace, "將")
docs <- tm_map(docs, toSpace, "更")
docs <- tm_map(docs, toSpace, "為")
docs <- tm_map(docs, toSpace, "這個")
docs <- tm_map(docs, toSpace, "‧")
docs <- tm_map(docs, toSpace, "我")
docs <- tm_map(docs, toSpace, "是")
docs <- tm_map(docs, toSpace, "看板")
docs <- tm_map(docs, toSpace, "網址")
docs <- tm_map(docs, toSpace, "標題")
docs <- tm_map(docs, toSpace, "來")
docs <- tm_map(docs, toSpace, "批踢踢實業坊")
docs <- tm_map(docs, toSpace, "[a-zA-Z]")
#移除標點符號(punctuation)
#移除數字跟空白(digits) (white space)
docs <- tm_map(docs, removePunctuation)
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, stripWhitespace)
mixseg = worker()
jieba_tokenizer=function(d){
unlist(segment(d[[1]],mixseg))
}
seg = lapply(docs, jieba_tokenizer)
freqFrame = as.data.frame(table(unlist(seg)))
freqFrame = freqFrame[order(freqFrame$Freq,decreasing=TRUE), ]
head(freqFrame)
library(knitr)
kable(head(freqFrame), format = "markdown")
rm(list=ls(all.names = TRUE))
#install.packages("http://download.r-forge.r-project.org/src/contrib/tmcn_0.1-4.tar.gz", repos = NULL, type = "source")
library(tmcn)
#install.packages("rvest")
library(rvest)
URL = "https://www.ptt.cc/bbs/IA/index.html"
html = read_html(URL)
title = html_nodes(html, "a")
href = html_attr(title, "href")
data = data.frame(title = toUTF8(html_text(title)), href = href)
View(data)
getContent <- function(href)
{
subURL = paste0("http://www.ptt.cc", href)
subhtml = read_html(subURL)
content = html_nodes(subhtml, "div#main-content.bbs-screen.bbs-content")
return(toUTF8(html_text(content)))
}
#practice
#getContent(data$href[14])
#clean
data = data[-c(1:10),]
#getContent(data$href[alltext])
allText = sapply(data$href, getContent)
allText
write.table(allText, "mydata.txt")
rm(list=ls(all.names = TRUE))
library(NLP)
library(tm)
library(jiebaRD)
library(jiebaR)
library(RColorBrewer)
library(wordcloud)
filenames <- list.files(getwd(), pattern="*.txt")
files <- lapply(filenames, readLines)
docs <- Corpus(VectorSource(files))
#Corpus是一種文字檔資料格式--文本
#移除可能有問題的符號-Corpus文本清理與改寫
toSpace <- content_transformer(function(x, pattern) {
return (gsub(pattern, " ", x))
}
)
docs <- tm_map(docs, toSpace, "的")
docs <- tm_map(docs, toSpace, "發信站")
docs <- tm_map(docs, toSpace, "文章")
docs <- tm_map(docs, toSpace, "作者")
docs <- tm_map(docs, toSpace, "推")
docs <- tm_map(docs, toSpace, "了")
docs <- tm_map(docs, toSpace, "不")
docs <- tm_map(docs, toSpace, "也")
docs <- tm_map(docs, toSpace, "都")
docs <- tm_map(docs, toSpace, "在")
docs <- tm_map(docs, toSpace, "有")
docs <- tm_map(docs, toSpace, "就")
docs <- tm_map(docs, toSpace, "會")
docs <- tm_map(docs, toSpace, "跟")
docs <- tm_map(docs, toSpace, "沒")
docs <- tm_map(docs, toSpace, "到")
docs <- tm_map(docs, toSpace, "為")
docs <- tm_map(docs, toSpace, "他")
docs <- tm_map(docs, toSpace, "們")
docs <- tm_map(docs, toSpace, "說")
docs <- tm_map(docs, toSpace, "與")
docs <- tm_map(docs, toSpace, "上")
docs <- tm_map(docs, toSpace, "對")
docs <- tm_map(docs, toSpace, "但")
docs <- tm_map(docs, toSpace, "只")
docs <- tm_map(docs, toSpace, "還")
docs <- tm_map(docs, toSpace, "和")
docs <- tm_map(docs, toSpace, "或")
docs <- tm_map(docs, toSpace, "從")
docs <- tm_map(docs, toSpace, "以")
docs <- tm_map(docs, toSpace, "被")
docs <- tm_map(docs, toSpace, "讓")
docs <- tm_map(docs, toSpace, "將")
docs <- tm_map(docs, toSpace, "更")
docs <- tm_map(docs, toSpace, "為")
docs <- tm_map(docs, toSpace, "這個")
docs <- tm_map(docs, toSpace, "‧")
docs <- tm_map(docs, toSpace, "我")
docs <- tm_map(docs, toSpace, "是")
docs <- tm_map(docs, toSpace, "看板")
docs <- tm_map(docs, toSpace, "網址")
docs <- tm_map(docs, toSpace, "標題")
docs <- tm_map(docs, toSpace, "來")
docs <- tm_map(docs, toSpace, "批踢踢實業坊")
docs <- tm_map(docs, toSpace, "[a-zA-Z]")
#移除標點符號(punctuation)
#移除數字跟空白(digits) (white space)
docs <- tm_map(docs, removePunctuation)
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, stripWhitespace)
mixseg = worker()
jieba_tokenizer=function(d){
unlist(segment(d[[1]],mixseg))
}
seg = lapply(docs, jieba_tokenizer)
freqFrame = as.data.frame(table(unlist(seg)))
freqFrame = freqFrame[order(freqFrame$Freq,decreasing=TRUE), ]
head(freqFrame)
library(knitr)
kable(head(freqFrame), format = "markdown")
par(family=("Heiti TC Light"))
wordcloud(freqFrame$Var1,freqFrame$Freq,
scale=c(5,0.1),min.freq=20,max.words=180,
random.order=TRUE, random.color=FALSE,
rot.per=.1, colors=brewer.pal(8, "Dark2"),
ordered.colors=FALSE,use.r.layout=FALSE,
fixed.asp=TRUE)
rm(list=ls(all.names = TRUE))
#install.packages("http://download.r-forge.r-project.org/src/contrib/tmcn_0.1-4.tar.gz", repos = NULL, type = "source")
library(tmcn)
#install.packages("rvest")
library(rvest)
URL = "https://www.ptt.cc/bbs/IA/index.html"
html = read_html(URL)
title = html_nodes(html, "a")
href = html_attr(title, "href")
data = data.frame(title = toUTF8(html_text(title)), href = href)
View(data)
rm(list=ls(all.names = TRUE))
#install.packages("http://download.r-forge.r-project.org/src/contrib/tmcn_0.1-4.tar.gz", repos = NULL, type = "source")
library(tmcn)
#install.packages("rvest")
library(rvest)
URL = "https://www.ptt.cc/bbs/IA/index.html"
html = read_html(URL)
title = html_nodes(html, "a")
href = html_attr(title, "href")
data = data.frame(title = toUTF8(html_text(title)), href = href)
View(data)
rm(list=ls(all.names = TRUE))
#install.packages("http://download.r-forge.r-project.org/src/contrib/tmcn_0.1-4.tar.gz", repos = NULL, type = "source")
library(tmcn)
#install.packages("rvest")
library(rvest)
URL = "https://www.ptt.cc/bbs/IA/index.html"
html = read_html(URL)
title = html_nodes(html, "a")
href = html_attr(title, "href")
data = data.frame(title = toUTF8(html_text(title)), href = href)
View(data)
getContent <- function(href)
{
subURL = paste0("http://www.ptt.cc", href)
subhtml = read_html(subURL)
content = html_nodes(subhtml, "div#main-content.bbs-screen.bbs-content")
return(toUTF8(html_text(content)))
}
#practice
#getContent(data$href[14])
#clean
#data = data[-c(1:10),]
#getContent(data$href[alltext])
#allText = sapply(data$href, getContent)
#allText
#write.table(allText, "mydata.txt")
rm(list=ls(all.names = TRUE))
library(NLP)
library(tm)
library(jiebaRD)
library(jiebaR)
library(RColorBrewer)
library(wordcloud)
filenames <- list.files(getwd(), pattern="*.txt")
files <- lapply(filenames, readLines)
docs <- Corpus(VectorSource(files))
#Corpus是一種文字檔資料格式--文本
#移除可能有問題的符號-Corpus文本清理與改寫
toSpace <- content_transformer(function(x, pattern) {
return (gsub(pattern, " ", x))
}
)
docs <- tm_map(docs, toSpace, "的")
docs <- tm_map(docs, toSpace, "發信站")
docs <- tm_map(docs, toSpace, "文章")
docs <- tm_map(docs, toSpace, "作者")
docs <- tm_map(docs, toSpace, "推")
docs <- tm_map(docs, toSpace, "了")
docs <- tm_map(docs, toSpace, "不")
docs <- tm_map(docs, toSpace, "也")
docs <- tm_map(docs, toSpace, "都")
docs <- tm_map(docs, toSpace, "在")
docs <- tm_map(docs, toSpace, "有")
docs <- tm_map(docs, toSpace, "就")
docs <- tm_map(docs, toSpace, "會")
docs <- tm_map(docs, toSpace, "跟")
docs <- tm_map(docs, toSpace, "沒")
docs <- tm_map(docs, toSpace, "到")
docs <- tm_map(docs, toSpace, "為")
docs <- tm_map(docs, toSpace, "他")
docs <- tm_map(docs, toSpace, "們")
docs <- tm_map(docs, toSpace, "說")
docs <- tm_map(docs, toSpace, "與")
docs <- tm_map(docs, toSpace, "上")
docs <- tm_map(docs, toSpace, "對")
docs <- tm_map(docs, toSpace, "但")
docs <- tm_map(docs, toSpace, "只")
docs <- tm_map(docs, toSpace, "還")
docs <- tm_map(docs, toSpace, "和")
docs <- tm_map(docs, toSpace, "或")
docs <- tm_map(docs, toSpace, "從")
docs <- tm_map(docs, toSpace, "以")
docs <- tm_map(docs, toSpace, "被")
docs <- tm_map(docs, toSpace, "讓")
docs <- tm_map(docs, toSpace, "將")
docs <- tm_map(docs, toSpace, "更")
docs <- tm_map(docs, toSpace, "為")
docs <- tm_map(docs, toSpace, "這個")
docs <- tm_map(docs, toSpace, "‧")
docs <- tm_map(docs, toSpace, "我")
docs <- tm_map(docs, toSpace, "是")
docs <- tm_map(docs, toSpace, "看板")
docs <- tm_map(docs, toSpace, "網址")
docs <- tm_map(docs, toSpace, "標題")
docs <- tm_map(docs, toSpace, "來")
docs <- tm_map(docs, toSpace, "批踢踢實業坊")
docs <- tm_map(docs, toSpace, "[a-zA-Z]")
#移除標點符號(punctuation)
#移除數字跟空白(digits) (white space)
docs <- tm_map(docs, removePunctuation)
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, stripWhitespace)
mixseg = worker()
jieba_tokenizer=function(d){
unlist(segment(d[[1]],mixseg))
}
seg = lapply(docs, jieba_tokenizer)
freqFrame = as.data.frame(table(unlist(seg)))
freqFrame = freqFrame[order(freqFrame$Freq,decreasing=TRUE), ]
head(freqFrame)
library(knitr)
kable(head(freqFrame), format = "markdown")
par(family=("Heiti TC Light"))
wordcloud(freqFrame$Var1,freqFrame$Freq,
scale=c(5,0.1),min.freq=20,max.words=180,
random.order=TRUE, random.color=FALSE,
rot.per=.1, colors=brewer.pal(8, "Dark2"),
ordered.colors=FALSE,use.r.layout=FALSE,
fixed.asp=TRUE)
rm(list=ls(all.names = TRUE))
#install.packages("http://download.r-forge.r-project.org/src/contrib/tmcn_0.1-4.tar.gz", repos = NULL, type = "source")
library(tmcn)
#install.packages("rvest")
library(rvest)
URL = "https://www.ptt.cc/bbs/IA/index.html"
html = read_html(URL)
title = html_nodes(html, "a")
href = html_attr(title, "href")
data = data.frame(title = toUTF8(html_text(title)), href = href)
View(data)
rm(list=ls(all.names = TRUE))
#install.packages("http://download.r-forge.r-project.org/src/contrib/tmcn_0.1-4.tar.gz", repos = NULL, type = "source")
library(tmcn)
#install.packages("rvest")
library(rvest)
URL = "https://www.ptt.cc/bbs/IA/index.html"
html = read_html(URL)
title = html_nodes(html, "a")
href = html_attr(title, "href")
data = data.frame(title = toUTF8(html_text(title)), href = href)
View(data)
rm(list=ls(all.names = TRUE))
#install.packages("http://download.r-forge.r-project.org/src/contrib/tmcn_0.1-4.tar.gz", repos = NULL, type = "source")
library(tmcn)
#install.packages("rvest")
library(rvest)
URL = "https://www.ptt.cc/bbs/IA/index.html"
html = read_html(URL)
title = html_nodes(html, "a")
href = html_attr(title, "href")
data = data.frame(title = toUTF8(html_text(title)), href = href)
View(data)
getContent <- function(href)
{
subURL = paste0("http://www.ptt.cc", href)
subhtml = read_html(subURL)
content = html_nodes(subhtml, "div#main-content.bbs-screen.bbs-content")
return(toUTF8(html_text(content)))
}
#practice
#getContent(data$href[14])
#clean
#data = data[-c(1:10),]
#getContent(data$href[alltext])
#allText = sapply(data$href, getContent)
#allText
#write.table(allText, "mydata.txt")
rm(list=ls(all.names = TRUE))
library(NLP)
library(tm)
library(jiebaRD)
library(jiebaR)
library(RColorBrewer)
library(wordcloud)
filenames <- list.files(getwd(), pattern="*.txt")
files <- lapply(filenames, readLines)
docs <- Corpus(VectorSource(files))
#Corpus是一種文字檔資料格式--文本
#移除可能有問題的符號-Corpus文本清理與改寫
toSpace <- content_transformer(function(x, pattern) {
return (gsub(pattern, " ", x))
}
)
docs <- tm_map(docs, toSpace, "的")
docs <- tm_map(docs, toSpace, "發信站")
docs <- tm_map(docs, toSpace, "文章")
docs <- tm_map(docs, toSpace, "作者")
docs <- tm_map(docs, toSpace, "推")
docs <- tm_map(docs, toSpace, "了")
docs <- tm_map(docs, toSpace, "不")
docs <- tm_map(docs, toSpace, "也")
docs <- tm_map(docs, toSpace, "都")
docs <- tm_map(docs, toSpace, "在")
docs <- tm_map(docs, toSpace, "有")
docs <- tm_map(docs, toSpace, "就")
docs <- tm_map(docs, toSpace, "會")
docs <- tm_map(docs, toSpace, "跟")
docs <- tm_map(docs, toSpace, "沒")
docs <- tm_map(docs, toSpace, "到")
docs <- tm_map(docs, toSpace, "為")
docs <- tm_map(docs, toSpace, "他")
docs <- tm_map(docs, toSpace, "們")
docs <- tm_map(docs, toSpace, "說")
docs <- tm_map(docs, toSpace, "與")
docs <- tm_map(docs, toSpace, "上")
docs <- tm_map(docs, toSpace, "對")
docs <- tm_map(docs, toSpace, "但")
docs <- tm_map(docs, toSpace, "只")
docs <- tm_map(docs, toSpace, "還")
docs <- tm_map(docs, toSpace, "和")
docs <- tm_map(docs, toSpace, "或")
docs <- tm_map(docs, toSpace, "從")
docs <- tm_map(docs, toSpace, "以")
docs <- tm_map(docs, toSpace, "被")
docs <- tm_map(docs, toSpace, "讓")
docs <- tm_map(docs, toSpace, "將")
docs <- tm_map(docs, toSpace, "更")
docs <- tm_map(docs, toSpace, "為")
docs <- tm_map(docs, toSpace, "及")
docs <- tm_map(docs, toSpace, "這個")
docs <- tm_map(docs, toSpace, "‧")
docs <- tm_map(docs, toSpace, "我")
docs <- tm_map(docs, toSpace, "是")
docs <- tm_map(docs, toSpace, "看板")
docs <- tm_map(docs, toSpace, "網址")
docs <- tm_map(docs, toSpace, "標題")
docs <- tm_map(docs, toSpace, "來")
docs <- tm_map(docs, toSpace, "批踢踢實業坊")
docs <- tm_map(docs, toSpace, "[a-zA-Z]")
#移除標點符號(punctuation)
#移除數字跟空白(digits) (white space)
docs <- tm_map(docs, removePunctuation)
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, stripWhitespace)
mixseg = worker()
jieba_tokenizer=function(d){
unlist(segment(d[[1]],mixseg))
}
seg = lapply(docs, jieba_tokenizer)
freqFrame = as.data.frame(table(unlist(seg)))
freqFrame = freqFrame[order(freqFrame$Freq,decreasing=TRUE), ]
head(freqFrame)
library(knitr)
kable(head(freqFrame), format = "markdown")
par(family=("Heiti TC Light"))
wordcloud(freqFrame$Var1,freqFrame$Freq,
scale=c(5,0.1),min.freq=20,max.words=180,
random.order=TRUE, random.color=FALSE,
rot.per=.1, colors=brewer.pal(8, "Dark2"),
ordered.colors=FALSE,use.r.layout=FALSE,
fixed.asp=TRUE)
